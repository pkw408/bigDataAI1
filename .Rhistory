title <- unlist(title) # 다시 백터형을 바꿔준다.
# 3) 신고라는 문자를 지워준다.
title <- gsub("신고","",title)
# 리뷰를 기억할 빈 변수를 선언합니다.
review = NULL
################FOR 문 ##################
# for(변수명 in 반복횟수) {
#   반복할 문장
#   ...
# }
# 변수 i가 1부터 5까지 1씩 중가하면서 반복
for(i in 1:5){
print(i)
}
# 변수가 i가 5부터 1까지 1씩 감소하면서 반복
for(i in 5:1){
print(i)
}
# 변수가 i가 1,3,5,7,9로 변경되면서 반복
for(i in c(1,3,5,7,9)){
print(i)
}
# seq(초기치, 최종치, by=증가치)
for(i in seq(1,10,2)){
print(i)
}
# by를 생략하고 증가치만 써도 가능하다.
for(i in seq(1,10)){
print(i)
}
# i가 10부터 1까지 2씩 감소한다.
for(i in seq(10,1,-2)){
print(i)
}
##############################################
for(i in seq(2,20,2)){
review = c(review, title[i]) # 짝수번째 자료를 추가해준다.
}
movie # 영화 제목
points # 평점
review # 영화 리뷰
# cbind() 함수를 사용해서 제목, 평점, 리뷰를 합쳐준다.
page <- cbind(movie,points)
page <- cbind(page,review)
# 웹 스크레이핑 된 데이터를 csv 파일로 저장시킨다.
write.csv(page,"movie_review.csv")
###############################################################################################################################
# 반복문을 사용해서 여러 패이지를 읽어오기
# https://movie.naver.com/movie/point/af/list.nhn?&page=i <- page 번호
# paste() 함수로 변경되지 않은 주소와 변경되는 주소를 이어 붙여서 읽어들일 페이지의 주소를 만듭니다.
# print(paste(url,I,sep=""))
for(i in seq(1,10)) {
url <- "https://movie.naver.com/movie/point/af/list.nhn?&page="
print(paste(url,i,seq=""))
}
# 한페이지를 읽어 들인 후 다음 페이지가 로딩되는 시간동안 잠시 스크레이핑을 멈춰주는 동작이 필요합니다. -> 페이지가 바뀔때 실행
# Sys,sleep(1) 1초
# 문제
# 네이버 평점 페이지를 1~3까지 크롤링하여 제목, 평점, 리뷰 를 합쳐 movie_revie.csv 파일로 저장합니다.
review = NULL
for(i in seq(1,3)) {
url <- "https://movie.naver.com/movie/point/af/list.nhn?&page="
url <- paste(url,i,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
Sys.sleep(1)
nodes <- html_nodes(content, ".movie") # 태그와 함꼐 데이터를 뽑아옴
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em") # > : div태크 list_netizen_score 안의 em
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}") # list 타입
title <- unlist(title) # 다시 백터형을 바꿔준다.
title <- gsub("신고","",title)
# 리뷰를 기억할 빈 변수를 선언합니다.
review = c(review, title[i]) # 짝수번째 자료를 추가해준다.
}
# 웹 스크레이핑 된 데이터를 csv 파일로 저장시킨다.
# cbind() 함수를 사용해서 제목, 평점, 리뷰를 합쳐준다.
page <- cbind(movie,points)
page <- cbind(page,review)
write.csv(page,"movie_review2.csv")
review = NULL
movie_review = NULL
for(i in seq(1,3)) {
url <- "https://movie.naver.com/movie/point/af/list.nhn?&page="
url <- paste(url,i,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
Sys.sleep(1)
nodes <- html_nodes(content, ".movie") # 태그와 함꼐 데이터를 뽑아옴
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em") # > : div태크 list_netizen_score 안의 em
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}") # list 타입
title <- unlist(title) # 다시 백터형을 바꿔준다.
title <- gsub("신고","",title)
# 리뷰를 기억할 빈 변수를 선언합니다.
for(i in seq(2,20,2)){
review = c(review, title[i]) # 짝수번째 자료를 추가해준다.
}
# cbind() 함수를 사용해서 제목, 평점, 리뷰를 합쳐준다.
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
write.csv(page,"movie_review2.csv")
review = NULL
movie_review = NULL
site <- "https://movie.naver.com/movie/point/af/list.nhn?&page="
for(i in seq(1,3)) {
url <- paste(site,i,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
Sys.sleep(1)
nodes <- html_nodes(content, ".movie") # 태그와 함꼐 데이터를 뽑아옴
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em") # > : div태크 list_netizen_score 안의 em
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}") # list 타입
title <- unlist(title) # 다시 백터형을 바꿔준다.
title <- gsub("신고","",title)
# 리뷰를 기억할 빈 변수를 선언합니다.
for(i in seq(2,20,2)){
review = c(review, title[i]) # 짝수번째 자료를 추가해준다.
}
# cbind() 함수를 사용해서 제목, 평점, 리뷰를 합쳐준다.
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
twitter <- read.csv('twitter.csv',fileEncoding = "UTF-8",header=T, stringsAsFactors = F) # UTF-8 인코딩 방식 설정정
class(twitter)
head(twitter)
# 데이터프레임의 변수 이름을 영어오 변경합니다.
# 내용(V5) 열을 ctx로 바꿔준다
# install.packages('dplyr')
library(dplyr) # rename을 사용하기 위해
twitter_copy <- rename(twitter, no='번호', id= '계정이름', writeDate = '작성일', tw = '내용')
head(twitter_copy)
# 특수 문자와 제어문자를 없애준다.
twitter_copy$tw <- gsub("[[:punct:][:cntrl:]]","",twitter_copy$tw)
# 형태소 분석 - 명사 추출
library(KoNLP)
nouns <- extractNoun(twitter_copy$tw)
class(nouns)
head(nouns)
# 백터형식을 풀어준다.
nouns <- unlist(nouns)
# 단어별 출현 빈도수를 계산하고 데이터 프레임으로 만들어준다.
wordCount <- table(nouns)
class(wordCount)
df_wordCount <- as.data.frame(wordCount) # 계산에 용이하게 데이터 프레임형태로 만들어준다,
class(df_wordCount)
# 데이터프레임의 변수 이름을 수정하고 2글자 이상인 6글자 이하인 단어만 뽑아냅니다.
df_wordCount <- rename(df_wordCount,words=nouns, freq=Freq)
df_wordCount$words<-gsub("^[0-9]*$","",df_wordCount$words) # 숫자제거
df_wordCount$words <- gsub(" ","",df_wordCount$word)         # 빈칸을 삭제
df_wordCount$words <-gsub("들이","",df_wordCount$words)
df_wordCount$words<-gsub("하게","",df_wordCount$words)
df_wordCount$words<-gsub("하지","",df_wordCount$words)
df_wordCount$words<-gsub("하기","",df_wordCount$words)
df_wordCount$words<-gsub("이유","",df_wordCount$words)
df_wordCount$words<-gsub("때문","",df_wordCount$words)
df_wordCount$words<-gsub("비롯","",df_wordCount$words)
# 상위 200개의 단어를 뽑아준다,
top200 <- df_wordCount %>% filter(nchar(words) >=2 & nchar(words) <= 6) %>%  arrange(desc(freq)) %>% head(200)
useSejongDic()  # 우리나라말 사전 등록
# 워드 클라우드를 만듭니다.
install.packages("wordcloud")
library(wordcloud)
library(RColorBrewer)
# brewer.pal(표현할 색상 개수, "팔레트 이름")
pal <- brewer.pal(8, "Dark2")
# 워드 클라우드를 만듭니다.
wordcloud(
words = top200$word,    # 표시할 단어 목록
freq = top200$freq,     # 단어의 출현 빈도
min.freq = 2,  # 단어의 최소 개수
max.word = 200, # 단어의 최대 개수
rot.per = 0.1, # 단어의 회전 비율(10% 설정)
random.order = F, # 빈도수 높은 단어를 중앙에 정렬 옵션 -- False  시킴
scale = c(7, 0.5), # 워드 클라우드의 단어 크기
colors = pal     # 단어의 표시할 색상 목록이 저장된 팔레트트
)
# 상위 20개의 단어들의 빈도수를 그래프로 그려라.
# 상위 20개의 단어를 뽑아준다,
top20 <- df_wordCount %>% filter(nchar(words) >=2 & nchar(words) <= 6) %>%  arrange(desc(freq)) %>% head(20)
library(ggplot2)
order_desc <- arrange(top20,desc(freq)) # 그래프의 순서를 지정해주기 위해 저장.
ggplot(top20, aes(words,freq)) + geom_col() + coord_flip() +
ylim(0,2500) +
scale_x_discrete(limit = order_desc$words) +
xlab("단어") +
ylab("빈도수") +
ggtitle("국정원 트윗 분석") +
geom_text(aes(label=freq), hjust=-1, color="#FF0000") # 글자색 설정가능
##############################################################################
install.packages("wordcloud")
review = NULL
movie_review = NULL
url <- NULL
site <- "https://movie.naver.com/movie/point/af/list.nhn?&page="
for(i in seq(1,3)) {
url <- paste(site,i,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
Sys.sleep(1)
nodes <- html_nodes(content, ".movie") # 태그와 함꼐 데이터를 뽑아옴
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em") # > : div태크 list_netizen_score 안의 em
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}") # list 타입
title <- unlist(title) # 다시 백터형을 바꿔준다.
title <- gsub("신고","",title)
# 리뷰를 기억할 빈 변수를 선언합니다.
for(i in seq(2,20,2)){
review = c(review, title[i]) # 짝수번째 자료를 추가해준다.
}
# cbind() 함수를 사용해서 제목, 평점, 리뷰를 합쳐준다.
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
library(rvest)
for(i in seq(1,3)) {
url <- paste(site,i,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
Sys.sleep(1)
nodes <- html_nodes(content, ".movie") # 태그와 함꼐 데이터를 뽑아옴
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em") # > : div태크 list_netizen_score 안의 em
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}") # list 타입
title <- unlist(title) # 다시 백터형을 바꿔준다.
title <- gsub("신고","",title)
# 리뷰를 기억할 빈 변수를 선언합니다.
for(i in seq(2,20,2)){
review = c(review, title[i]) # 짝수번째 자료를 추가해준다.
}
# cbind() 함수를 사용해서 제목, 평점, 리뷰를 합쳐준다.
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
url <- paste(site,1,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
# 스크레이핑 할 웹 사이트 주소를 지정합니다.
url <- "https://movie.naver.com/movie/point/af/list.nhn"
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
url <- paste(site,i,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
site <- 'https://movie.naver.com/movie/point/af/list.nhn?&page='
site <- 'https://movie.naver.com/movie/point/af/list.nhn?&page='
url <- paste(site,i,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
# 데이터프레임의 변수 이름을 영어오 변경합니다.
# 내용(V5) 열을 ctx로 바꿔준다
# install.packages('dplyr')
library(dplyr) # rename을 사용하기 위해
# 형태소 분석 - 명사 추출
library(KoNLP)
library(wordcloud)
library(RColorBrewer)
library(ggplot2)
#[:punct:] (출력 가능한 (눈에 보이는) 특수 문자)      # 위 3가지 다양한 함수(같은역할)
library(stringr) # gusb을 사용하기 위해
library(rvest)
review = NULL
movie_review = NULL
url <- NULL
site <- 'https://movie.naver.com/movie/point/af/list.nhn?&page='
for(i in seq(1,3)) {
url <- paste(site,i,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
Sys.sleep(1)
nodes <- html_nodes(content, ".movie") # 태그와 함꼐 데이터를 뽑아옴
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em") # > : div태크 list_netizen_score 안의 em
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}") # list 타입
title <- unlist(title) # 다시 백터형을 바꿔준다.
title <- gsub("신고","",title)
# 리뷰를 기억할 빈 변수를 선언합니다.
for(i in seq(2,20,2)){
review = c(review, title[i]) # 짝수번째 자료를 추가해준다.
}
# cbind() 함수를 사용해서 제목, 평점, 리뷰를 합쳐준다.
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
rm(txt)
url <- paste(site,i,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
for(i in seq(1,3)) {
url <- paste(site,i,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
Sys.sleep(1)
nodes <- html_nodes(content, ".movie") # 태그와 함꼐 데이터를 뽑아옴
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em") # > : div태크 list_netizen_score 안의 em
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}") # list 타입
title <- unlist(title) # 다시 백터형을 바꿔준다.
title <- gsub("신고","",title)
# 리뷰를 기억할 빈 변수를 선언합니다.
for(i in seq(2,20,2)){
review = c(review, title[i]) # 짝수번째 자료를 추가해준다.
}
# cbind() 함수를 사용해서 제목, 평점, 리뷰를 합쳐준다.
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
site <- "https://movie.naver.com/movie/point/af/list.nhn?&page="
for(i in seq(1,3)) {
url <- paste(site,i,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
Sys.sleep(1)
nodes <- html_nodes(content, ".movie") # 태그와 함꼐 데이터를 뽑아옴
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em") # > : div태크 list_netizen_score 안의 em
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}") # list 타입
title <- unlist(title) # 다시 백터형을 바꿔준다.
title <- gsub("신고","",title)
# 리뷰를 기억할 빈 변수를 선언합니다.
for(i in seq(2,20,2)){
review = c(review, title[i]) # 짝수번째 자료를 추가해준다.
}
# cbind() 함수를 사용해서 제목, 평점, 리뷰를 합쳐준다.
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
url <- paste(site,i,seq="")
site <- "https://movie.naver.com/movie/point/af/list.nhn?&page="
for(i in seq(1,3)) {
url <- paste(site,i,seq="")
content <- read_html(url, encoding = "CP949") # UTF-8은 사용하면 안된다. / 해당 url의 페이지를 가져옴.
Sys.sleep(1)
nodes <- html_nodes(content, ".movie") # 태그와 함꼐 데이터를 뽑아옴
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em") # > : div태크 list_netizen_score 안의 em
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}") # list 타입
title <- unlist(title) # 다시 백터형을 바꿔준다.
title <- gsub("신고","",title)
# 리뷰를 기억할 빈 변수를 선언합니다.
for(i in seq(2,20,2)){
review = c(review, title[i]) # 짝수번째 자료를 추가해준다.
}
# cbind() 함수를 사용해서 제목, 평점, 리뷰를 합쳐준다.
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
for(i in seq(1,3)) {
url <- paste(site,i,seq="")
content <- read_html(url, encoding = "CP949")
Sys.sleep(1)
nodes <- html_nodes(content, ".movie")
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em")
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}")
title <- unlist(title)
title <- gsub("신고","",title)
for(i in seq(2,20,2)){
review = c(review, title[i])
}
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
for(i in seq(1,3)) {
url <- paste(site,i,seq="")
content <- read_html(url, encoding = "CP949")
Sys.sleep(1)
}
site <- "https://movie.naver.com/movie/point/af/list.nhn?&page="
review = NULL
movie_review = NULL
url <- NULL
site <- "https://movie.naver.com/movie/point/af/list.nhn?&page="
site <- "https://movie.naver.com/movie/point/af/list.nhn?&page="
for(i in seq(1,3)) {
url <- paste(site,i,seq="")
print(url)
content <- read_html(url, encoding = "CP949")
Sys.sleep(1)
nodes <- html_nodes(content, ".movie")
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em")
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}")
title <- unlist(title)
title <- gsub("신고","",title)
for(i in seq(2,20,2)){
review = c(review, title[i])
}
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
for(i in 1:3) {
url <- paste(site,i,seq="")
print(url)
content <- read_html(url, encoding = "CP949")
Sys.sleep(1)
nodes <- html_nodes(content, ".movie")
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em")
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}")
title <- unlist(title)
title <- gsub("신고","",title)
for(i in seq(2,20,2)){
review = c(review, title[i])
}
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
url <- paste(site,i,seq=" ")
for(i in 1:3) {
url <- paste(site,i,seq="")
print(url)
content <- read_html(site, encoding = "CP949")
Sys.sleep(1)
nodes <- html_nodes(content, ".movie")
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em")
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}")
title <- unlist(title)
title <- gsub("신고","",title)
for(i in seq(2,20,2)){
review = c(review, title[i])
}
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
for(num in 1:3) {
url <- paste(site,i,seq="")
print(url)
content <- read_html(url, encoding = "CP949")
Sys.sleep(1)
nodes <- html_nodes(content, ".movie")
movie <- html_text(nodes, trim=T)
nodes <- html_nodes(content, "div.list_netizen_score > em")
points <- html_text(nodes, trim=T)
nodes <- html_nodes(content,".title")
title <- html_text(nodes, trim=T)
title <- gsub("[[:cntrl:]]","",title)
title <- strsplit(title, "중[0-9]{1,2}")
title <- unlist(title)
title <- gsub("신고","",title)
for(i in seq(2,20,2)){
review = c(review, title[i])
}
page <- cbind(movie,points)
page <- cbind(page,review)
movie_review <- rbind(movie_review,page)
}
url_copy <- NULL
site_copy <- "https://movie.naver.com/movie/point/af/list.nhn?&page="
url_copy <- paste(site_copy,i,seq="")
print(url_copy)
content <- read_html(url, encoding = "CP949")
review = NULL
movie_review = NULL
url_copy <- NULL
site_copy <- "https://movie.naver.com/movie/point/af/list.nhn?&page="
